You are a senior AI engineer building a production-ready Web-Browsing Research Agent using LangChain and the OpenAI API in Python. The goal is to create an autonomous agent that accepts a research query from the command line, breaks the query into logical sub-questions, searches the web using appropriate tools, synthesizes information from multiple sources, and produces a structured, professional research report. The agent must follow a ReAct or OpenAI tool-calling pattern and be suitable as a portfolio-quality project.

The implementation must use Python 3.10 or newer and the LangChain framework, with the OpenAI API accessed exclusively through the ChatOpenAI interface. The default model should be gpt-4o-mini, but the design should allow easy configuration. The agent should be executable via a CLI command such as `python main.py "your research query"`. All secrets, including the OpenAI API key and any search API keys, must be loaded strictly from environment variables, with no hard-coded credentials anywhere in the codebase.

The agent’s behavior must include deliberate planning before acting. It should interpret the research goal, decompose it into meaningful sub-questions, and decide which steps require web searches versus internal reasoning. During research, it should use a web search tool such as DuckDuckGo, Tavily, or SerpAPI to retrieve up-to-date information from credible and authoritative sources. The agent must extract factual insights, comparisons, examples, and clear pros and cons rather than shallow summaries. During synthesis, it must combine information across sources, resolve conflicts logically, paraphrase content in its own words, and explicitly acknowledge uncertainty when information is incomplete or conflicting. The agent must never hallucinate facts or copy source text verbatim.

The final output must be a clean, well-structured report printed to standard output only. The report must follow this exact structure: a “Research Summary” heading followed by sections titled Objective, Key Findings, Detailed Analysis, Pros & Cons, Final Recommendation, and Sources. Internal chain-of-thought, planning steps, or tool traces must never appear in the final output. Verbose logging may be enabled internally for debugging, but only the final report should be displayed to the user.

A custom system prompt must be created that defines the agent as an autonomous web research agent, instructs it to follow a plan-search-reason-synthesize workflow, forbids hallucination, and requires transparency about uncertainty, while explicitly hiding internal reasoning. The ChatOpenAI instance must be initialized with a temperature of zero. Tools must be registered using LangChain’s tool interface, and the agent executor must include a maximum iteration limit and graceful error handling for tool failures, empty search results, and API errors.

The project must follow a strict file structure consisting of main.py as the CLI entry point, agent.py for agent creation logic, tools.py for web search and utility tools, prompts.py for system and human prompts, requirements.txt for dependencies, and a README.md. The code must be clean, readable, well-commented, and follow current LangChain best practices with no deprecated APIs, unused code, or TODO placeholders. Functions should be small and reusable, with type hints where appropriate.

The README must include a clear project overview, a brief explanation of the agent architecture, setup instructions, required environment variables, example CLI usage, and suggested extensions such as conversational memory, multi-agent collaboration, or a LangGraph-based implementation. The final output of this task must be complete, runnable code for all files, with minimal explanation outside of code blocks, suitable for review by senior AI engineers and inclusion in a professional portfolio.
