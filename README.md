# Web Research Agent ðŸ”

A production-ready autonomous web research agent built with LangChain and OpenAI. This agent accepts natural language research queries, intelligently breaks them into sub-questions, searches the web for current information, and synthesizes findings into professional, structured reports.

## Features

- ðŸ¤– **Autonomous Research** - Automatically plans, searches, and synthesizes information
- ðŸ”Ž **Multi-Provider Search** - Supports Tavily, SerpAPI, and DuckDuckGo
- ðŸ“Š **Structured Reports** - Clean, professional output with sources
- âš™ï¸ **Type-Safe Configuration** - Pydantic-based settings management
- ðŸ›¡ï¸ **Production-Ready** - Proper error handling, logging, and best practices
- ðŸ”Œ **Extensible** - Easy to add new search providers or tools

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Query                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Research Agent                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Planning Phase                         â”‚  â”‚
â”‚  â”‚    â€¢ Analyze research goal                                â”‚  â”‚
â”‚  â”‚    â€¢ Decompose into sub-questions                         â”‚  â”‚
â”‚  â”‚    â€¢ Prioritize information needs                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Research Phase                          â”‚  â”‚
â”‚  â”‚    â€¢ Tavily Search (AI-optimized)                         â”‚  â”‚
â”‚  â”‚    â€¢ SerpAPI (Google results)                             â”‚  â”‚
â”‚  â”‚    â€¢ DuckDuckGo (fallback)                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Synthesis Phase                         â”‚  â”‚
â”‚  â”‚    â€¢ Cross-reference sources                              â”‚  â”‚
â”‚  â”‚    â€¢ Resolve conflicts                                    â”‚  â”‚
â”‚  â”‚    â€¢ Generate structured report                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Structured Report                             â”‚
â”‚    â€¢ Objective       â€¢ Pros & Cons                              â”‚
â”‚    â€¢ Key Findings    â€¢ Final Recommendation                     â”‚
â”‚    â€¢ Analysis        â€¢ Sources                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
web-research-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py           # Package initialization
â”‚   â”œâ”€â”€ config.py             # Pydantic settings management
â”‚   â”œâ”€â”€ exceptions.py         # Custom exception classes
â”‚   â”œâ”€â”€ logging_config.py     # Structured logging setup
â”‚   â”œâ”€â”€ prompts.py            # System and human prompts
â”‚   â”œâ”€â”€ agent.py              # ResearchAgent class
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ __init__.py       # Tool exports
â”‚       â”œâ”€â”€ registry.py       # Tool registry and discovery
â”‚       â”œâ”€â”€ tavily_search.py  # Tavily search implementation
â”‚       â”œâ”€â”€ serpapi_search.py # SerpAPI search implementation
â”‚       â””â”€â”€ duckduckgo_search.py  # DuckDuckGo fallback
â”œâ”€â”€ main.py                   # CLI entry point
â”œâ”€â”€ pyproject.toml            # Modern Python packaging
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ .env.example              # Environment template
â””â”€â”€ README.md                 # Documentation
```

## Quick Start

### 1. Clone and Install

```bash
# Clone the repository
git clone https://github.com/yourusername/web-research-agent.git
cd web-research-agent

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
# Copy the example environment file
cp .env.example .env

# Edit .env and add your API keys
```

### 3. Run Research

```bash
python main.py "What are the latest trends in AI?"
```

## Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `OPENAI_API_KEY` | âœ… Yes | - | OpenAI API key |
| `OPENAI_MODEL` | No | `gpt-4o-mini` | Model to use |
| `OPENAI_TEMPERATURE` | No | `0.0` | Response temperature |
| `TAVILY_API_KEY` | â­ Recommended | - | Tavily API key ([free](https://tavily.com)) |
| `SERPAPI_API_KEY` | No | - | SerpAPI key |
| `MAX_ITERATIONS` | No | `25` | Max agent iterations |
| `LOG_LEVEL` | No | `WARNING` | Logging level |

### Search Providers

| Provider | API Key | Best For |
|----------|---------|----------|
| **Tavily** | Required | AI-optimized results (recommended) |
| **SerpAPI** | Required | Google search results |
| **DuckDuckGo** | None | Free fallback |

## Usage

### Basic Usage

```bash
python main.py "your research query"
```

### With Options

```bash
# Use a specific model
python main.py "Compare React vs Vue.js" --model gpt-4o

# Enable verbose logging
python main.py "Latest AI developments" --verbose

# Save to file
python main.py "Elon Musk net worth" --output report.txt

# Increase iteration limit
python main.py "Complex research topic" --max-iterations 40
```

### CLI Arguments

| Argument | Short | Default | Description |
|----------|-------|---------|-------------|
| `query` | - | Required | Research query |
| `--model` | - | From config | OpenAI model |
| `--max-iterations` | - | `25` | Max iterations |
| `--verbose` | `-v` | `False` | Debug logging |
| `--output` | `-o` | stdout | Output file |

### Programmatic Usage

```python
from src.agent import create_agent

# Create agent
agent = create_agent(model="gpt-4o-mini")

# Run research
result = agent.research("What is quantum computing?")

# Access result
print(result.content)
print(f"Success: {result.success}")
```

### Async Usage

```python
import asyncio
from src.agent import create_agent

async def main():
    agent = create_agent()
    result = await agent.research_async("Latest AI news")
    print(result.content)

asyncio.run(main())
```

## Output Format

Reports are structured with these sections:

1. **Objective** - What was researched
2. **Key Findings** - 3-5 critical discoveries
3. **Detailed Analysis** - In-depth exploration
4. **Pros & Cons** - Balanced assessment
5. **Final Recommendation** - Evidence-based conclusion
6. **Sources** - Cited references

## Error Handling

The agent handles various failure modes gracefully:

```python
from src.exceptions import (
    ConfigurationError,
    SearchError,
    AgentExecutionError,
    EmptyResponseError,
)

try:
    result = agent.research(query)
except ConfigurationError as e:
    print(f"Config issue: {e}")
except SearchError as e:
    print(f"Search failed ({e.provider}): {e}")
except AgentExecutionError as e:
    print(f"Agent error: {e}")
```

## Development

### Install Dev Dependencies

```bash
pip install -e ".[dev]"
```

### Code Quality

```bash
# Format code
black src/ main.py

# Lint code
ruff check src/ main.py

# Type check
mypy src/

# Run tests
pytest
```

## Extending

### Add a New Search Provider

1. Create `src/tools/your_provider.py`:

```python
from langchain_core.tools import tool
from src.logging_config import get_logger

logger = get_logger(__name__)

@tool
def your_search(query: str, max_results: int = 5) -> str:
    """Your search tool description."""
    # Implementation
    pass
```

2. Register in `src/tools/registry.py`:

```python
from src.tools.your_provider import your_search

_TOOL_REGISTRY["your_search"] = your_search
```

## License

MIT License - See [LICENSE](LICENSE) for details.

---

Built with [LangChain](https://langchain.com), [LangGraph](https://langchain-ai.github.io/langgraph/), and [OpenAI](https://openai.com)
